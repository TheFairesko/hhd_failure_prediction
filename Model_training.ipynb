{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считываем данные и разбиваем их на тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_for_models.csv') as f:\n",
    "    data = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = data.select_dtypes(include='number').columns.tolist() # оставляю только числовые столбцы\n",
    "\n",
    "data = data.astype({\n",
    "    col: 'int64' for col in numeric_cols \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikita\\AppData\\Local\\Temp\\ipykernel_7812\\204938430.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.33, random_state=random_state))\n"
     ]
    }
   ],
   "source": [
    "random_state = 2025 # нужен для повторяемости результатов\n",
    "\n",
    "pos_data = data.query(\"target == 1\")\n",
    "\n",
    "# оставляем только 33% случайных сэмплов класса 0 для каждого диска\n",
    "neg_data = (\n",
    "    data\n",
    "    .query(\"target == 0\")\n",
    "    .groupby(\"serial_number\", as_index=False)\n",
    "    .apply(lambda x: x.sample(frac=0.33, random_state=random_state))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# новый датасет\n",
    "data = pd.concat((neg_data, pos_data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['serial_number', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smart_5_last</th>\n",
       "      <th>smart_9_last</th>\n",
       "      <th>smart_187_last</th>\n",
       "      <th>smart_188_last</th>\n",
       "      <th>smart_192_last</th>\n",
       "      <th>smart_198_last</th>\n",
       "      <th>smart_199_last</th>\n",
       "      <th>smart_240_last</th>\n",
       "      <th>smart_241_last</th>\n",
       "      <th>smart_242_last</th>\n",
       "      <th>block</th>\n",
       "      <th>smart_5_diff</th>\n",
       "      <th>smart_187_diff</th>\n",
       "      <th>smart_198_diff</th>\n",
       "      <th>smart_199_max</th>\n",
       "      <th>AUC_smart_5_raw</th>\n",
       "      <th>AUC_smart_187_raw</th>\n",
       "      <th>AUC_smart_198_raw</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15948</td>\n",
       "      <td>98121318264</td>\n",
       "      <td>234810359494</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13097</td>\n",
       "      <td>88405181240</td>\n",
       "      <td>194441877008</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5939</td>\n",
       "      <td>62977305968</td>\n",
       "      <td>106747494514</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3553</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3110</td>\n",
       "      <td>43138957032</td>\n",
       "      <td>69458441764</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6653</td>\n",
       "      <td>66249905800</td>\n",
       "      <td>115393592954</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218623</th>\n",
       "      <td>0</td>\n",
       "      <td>15943</td>\n",
       "      <td>820</td>\n",
       "      <td>4295032833</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15527</td>\n",
       "      <td>87198911944</td>\n",
       "      <td>233614901482</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23780</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219435</th>\n",
       "      <td>0</td>\n",
       "      <td>13306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13086</td>\n",
       "      <td>83943199456</td>\n",
       "      <td>204123480846</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225958</th>\n",
       "      <td>0</td>\n",
       "      <td>7243</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>6840</td>\n",
       "      <td>58561660336</td>\n",
       "      <td>88530467778</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>2160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226309</th>\n",
       "      <td>0</td>\n",
       "      <td>6186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5797</td>\n",
       "      <td>55168531248</td>\n",
       "      <td>74917161090</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237701</th>\n",
       "      <td>0</td>\n",
       "      <td>10303</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>9751</td>\n",
       "      <td>69443093936</td>\n",
       "      <td>131518997730</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>924</td>\n",
       "      <td>1320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79779 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        smart_5_last  smart_9_last  smart_187_last  smart_188_last  \\\n",
       "0                  0         16507               0               0   \n",
       "1                  0         13631               0               0   \n",
       "2                  0          6429               0               0   \n",
       "3                  0          3553               0               0   \n",
       "4                  0          7147               0               0   \n",
       "...              ...           ...             ...             ...   \n",
       "218623             0         15943             820      4295032833   \n",
       "219435             0         13306               0               0   \n",
       "225958             0          7243              18               0   \n",
       "226309             0          6186               0               0   \n",
       "237701             0         10303              34               0   \n",
       "\n",
       "        smart_192_last  smart_198_last  smart_199_last  smart_240_last  \\\n",
       "0                    3               0               0           15948   \n",
       "1                    3               0               0           13097   \n",
       "2                    3               0               0            5939   \n",
       "3                    0               0               0            3110   \n",
       "4                    3               0               0            6653   \n",
       "...                ...             ...             ...             ...   \n",
       "218623              16               0               0           15527   \n",
       "219435               3               0               0           13086   \n",
       "225958               0              96               0            6840   \n",
       "226309               0               0               0            5797   \n",
       "237701               1              64               0            9751   \n",
       "\n",
       "        smart_241_last  smart_242_last  block  smart_5_diff  smart_187_diff  \\\n",
       "0          98121318264    234810359494     23             0               0   \n",
       "1          88405181240    194441877008     19             0               0   \n",
       "2          62977305968    106747494514      9             0               0   \n",
       "3          43138957032     69458441764      5             0               0   \n",
       "4          66249905800    115393592954     10             0               0   \n",
       "...                ...             ...    ...           ...             ...   \n",
       "218623     87198911944    233614901482     22             0               0   \n",
       "219435     83943199456    204123480846     19             0               0   \n",
       "225958     58561660336     88530467778     10             0              10   \n",
       "226309     55168531248     74917161090      9             0               0   \n",
       "237701     69443093936    131518997730     14             0               3   \n",
       "\n",
       "        smart_198_diff  smart_199_max  AUC_smart_5_raw  AUC_smart_187_raw  \\\n",
       "0                    0              0                0                  0   \n",
       "1                    0              0                0                  0   \n",
       "2                    0              0                0                  0   \n",
       "3                    0              0                0                  0   \n",
       "4                    0              0                0                  0   \n",
       "...                ...            ...              ...                ...   \n",
       "218623               0              0                0              23780   \n",
       "219435               0              0                0                  0   \n",
       "225958              32              0                0                327   \n",
       "226309               0              0                0                  0   \n",
       "237701              16              0                0                924   \n",
       "\n",
       "        AUC_smart_198_raw  target  \n",
       "0                       0       0  \n",
       "1                       0       0  \n",
       "2                       0       0  \n",
       "3                       0       0  \n",
       "4                       0       0  \n",
       "...                   ...     ...  \n",
       "218623                  0       1  \n",
       "219435                  0       1  \n",
       "225958               2160       1  \n",
       "226309                  0       1  \n",
       "237701               1320       1  \n",
       "\n",
       "[79779 rows x 19 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Т.к. нам нужно, чтобы в тестовой выборки с реальными данными не осталось 2-3 экземпляра класса 1 - проведём следующее разделение\n",
    "\n",
    "# Разделяем данные класса 1 и класса 0\n",
    "class_1 = data[data['target'] == 1]\n",
    "class_0 = data[data['target'] == 0]\n",
    "\n",
    "# Фиксируем 30 объектов класса 1 для тестовой выборки (можно попробовать взять меньше - больше)\n",
    "class_1_train, class_1_test = train_test_split(class_1, test_size=30, random_state=random_state)\n",
    "\n",
    "# Добавляем пропорциональное количество данных класса 0\n",
    "class_0_train, class_0_test = train_test_split(class_0, test_size=len(class_1_test) * 10, random_state=random_state)\n",
    "\n",
    "# Собираем тренировочные и тестовые выборки\n",
    "train_data = pd.concat([class_1_train, class_0_train])\n",
    "test_data = pd.concat([class_1_test, class_0_test])\n",
    "\n",
    "# Перемешиваем данные\n",
    "train_data = train_data.sample(frac=1, random_state=random_state).reset_index()\n",
    "test_data = test_data.sample(frac=1, random_state=random_state).reset_index()\n",
    "\n",
    "# Разделяем на X и y для обучения и теста\n",
    "X_train, y_train = train_data.drop(columns=['target']), train_data['target']\n",
    "X_test, y_test = test_data.drop(columns=['target']), test_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отдельное обучение одной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение модели и кросс-валидации\n",
    "clf = RandomForestClassifier(random_state=random_state)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Заводим массив для метрик кросс-валидации\n",
    "roc_auc_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Кросс-валидация с балансировкой данных с помощью SMOTEENN\n",
    "for train_idx, val_idx in tqdm(cv.split(X_train, y_train), total=cv.get_n_splits(), desc=\"Cross-validation\"):\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    smote_enn = SMOTEENN(random_state=random_state)\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Обучение модели на синтетических данных\n",
    "    clf.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Оценка на валидационной выборке (реальные данные)\n",
    "    y_val_pred = clf.predict(X_fold_val)\n",
    "    y_val_pred_proba = clf.predict_proba(X_fold_val)[:, 1]\n",
    "    \n",
    "    # Расчёт метрик\n",
    "    roc_auc = roc_auc_score(y_fold_val, y_val_pred_proba)\n",
    "    precision = precision_score(y_fold_val, y_val_pred)\n",
    "    recall = recall_score(y_fold_val, y_val_pred)\n",
    "    f1 = f1_score(y_fold_val, y_val_pred)\n",
    "    \n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Вывод метрик кросс-валидации\n",
    "print(f\"Средний ROC-AUC: {np.mean(roc_auc_scores):.4f} ± {np.std(roc_auc_scores):.4f}\")\n",
    "print(f\"Средний Precision: {np.mean(precision_scores):.4f} ± {np.std(precision_scores):.4f}\")\n",
    "print(f\"Средний Recall: {np.mean(recall_scores):.4f} ± {np.std(recall_scores):.4f}\")\n",
    "print(f\"Средний F1-Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
    "\n",
    "# Финальное тестирование на реальных данных\n",
    "smote_enn = SMOTEENN(random_state=random_state)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nКлассификационный отчет на тестовых данных (реальные данные):\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "print(f\"ROC-AUC на тестовых данных: {roc_auc_score(y_test, y_test_pred_proba):.4f}\")\n",
    "print(f\"Precision на тестовых данных: {precision_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Recall на тестовых данных: {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"F1-Score на тестовых данных: {f1_score(y_test, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение сразу нескольких моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение модели: Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV:   0%|          | 0/5 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m y_fold_train, y_fold_val \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39miloc[train_idx], y_train\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[0;32m     30\u001b[0m smote_enn \u001b[38;5;241m=\u001b[39m SMOTEENN(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m---> 31\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote_enn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fold_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_fold_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Обучение модели на синтетических данных\u001b[39;00m\n\u001b[0;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_resampled, y_resampled)\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\imblearn\\base.py:202\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\imblearn\\base.py:105\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m     99\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    103\u001b[0m )\n\u001b[1;32m--> 105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    111\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:160\u001b[0m, in \u001b[0;36mSMOTEENN._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy\n\u001b[0;32m    159\u001b[0m X_res, y_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmote_\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menn_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\imblearn\\base.py:202\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\imblearn\\base.py:105\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m     99\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    103\u001b[0m )\n\u001b[1;32m--> 105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    111\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_edited_nearest_neighbours.py:168\u001b[0m, in \u001b[0;36mEditedNearestNeighbours._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    166\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[0;32m    167\u001b[0m y_class \u001b[38;5;241m=\u001b[39m _safe_indexing(y, target_class_indices)\n\u001b[1;32m--> 168\u001b[0m nnhood_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    169\u001b[0m nnhood_label \u001b[38;5;241m=\u001b[39m y[nnhood_idx]\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind_sel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:905\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    903\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 905\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    906\u001b[0m         pairwise_distances_chunked(\n\u001b[0;32m    907\u001b[0m             X,\n\u001b[0;32m    908\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[0;32m    909\u001b[0m             reduce_func\u001b[38;5;241m=\u001b[39mreduce_func,\n\u001b[0;32m    910\u001b[0m             metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_,\n\u001b[0;32m    911\u001b[0m             n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    912\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2261\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2260\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m D_chunk\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 2261\u001b[0m     D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mreduce_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2262\u001b[0m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[0;32m   2263\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m D_chunk\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:749\u001b[0m, in \u001b[0;36mKNeighborsMixin._kneighbors_reduce_func\u001b[1;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reduce a chunk of distances to the nearest neighbors.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \n\u001b[0;32m    724\u001b[0m \u001b[38;5;124;03mCallback to :func:`sklearn.metrics.pairwise.pairwise_distances_chunked`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;124;03m    The neighbors indices.\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    748\u001b[0m sample_range \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(dist\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m--> 749\u001b[0m neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    750\u001b[0m neigh_ind \u001b[38;5;241m=\u001b[39m neigh_ind[:, :n_neighbors]\n\u001b[0;32m    751\u001b[0m \u001b[38;5;66;03m# argpartition doesn't guarantee sorted order, so we sort again\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:858\u001b[0m, in \u001b[0;36margpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argpartition_dispatcher)\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21margpartition\u001b[39m(a, kth, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintroselect\u001b[39m\u001b[38;5;124m'\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    781\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;124;03m    Perform an indirect partition along the given axis using the\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;124;03m    algorithm specified by the `kind` keyword. It returns an array of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    856\u001b[0m \n\u001b[0;32m    857\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 858\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margpartition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Определение моделей\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=random_state, max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(random_state=random_state),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=random_state),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=random_state),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=random_state)\n",
    "}\n",
    "\n",
    "# Определение кросс-валидации\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Массив для хранения результатов метрик по каждой моделей\n",
    "results = []\n",
    "\n",
    "# Обучение для каждой модели\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nОбучение модели: {model_name}\")\n",
    "    roc_auc_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Кросс-валидация с балансировкой данных с помощью SMOTEENN\n",
    "    for train_idx, val_idx in tqdm(cv.split(X_train, y_train), total=cv.get_n_splits(), desc=f\"{model_name} CV\"):\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        smote_enn = SMOTEENN(random_state=random_state)\n",
    "        X_resampled, y_resampled = smote_enn.fit_resample(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Обучение модели на синтетических данных\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "\n",
    "        # Оценка на валидационной выборке (реальные данные)\n",
    "        y_val_pred = model.predict(X_fold_val)\n",
    "        y_val_pred_proba = model.predict_proba(X_fold_val)[:, 1]\n",
    "\n",
    "        roc_auc = roc_auc_score(y_fold_val, y_val_pred_proba)\n",
    "        precision = precision_score(y_fold_val, y_val_pred)\n",
    "        recall = recall_score(y_fold_val, y_val_pred)\n",
    "        f1 = f1_score(y_fold_val, y_val_pred)\n",
    "\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Сохранение средних значений метрик\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"ROC-AUC (CV)\": f\"{np.mean(roc_auc_scores):.4f} ± {np.std(roc_auc_scores):.4f}\",\n",
    "        \"Precision (CV)\": f\"{np.mean(precision_scores):.4f} ± {np.std(precision_scores):.4f}\",\n",
    "        \"Recall (CV)\": f\"{np.mean(recall_scores):.4f} ± {np.std(recall_scores):.4f}\",\n",
    "        \"F1-Score (CV)\": f\"{np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\"\n",
    "    })\n",
    "\n",
    "    # Финальное тестирование на реальных данных\n",
    "    smote_enn = SMOTEENN(random_state=random_state)\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    test_metrics = {\n",
    "        \"ROC-AUC (Test)\": roc_auc_score(y_test, y_test_pred_proba),\n",
    "        \"Precision (Test)\": precision_score(y_test, y_test_pred),\n",
    "        \"Recall (Test)\": recall_score(y_test, y_test_pred),\n",
    "        \"F1-Score (Test)\": f1_score(y_test, y_test_pred)\n",
    "    }\n",
    "\n",
    "    # Добавление тестовых метрик в финальные результаты\n",
    "    results[-1].update({key: f\"{value:.4f}\" for key, value in test_metrics.items()})\n",
    "\n",
    "# Вывод таблицы результатов\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nРезультаты моделей:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results/models_results_resampled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение с помощью балансировки весов классов (class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение модели: Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV: 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение модели: Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Forest CV: 100%|██████████| 5/5 [00:25<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение модели: Extra Trees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extra Trees CV: 100%|██████████| 5/5 [00:12<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение модели: LightGBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM CV:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 111, number of negative: 63448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2095\n",
      "[LightGBM] [Info] Number of data points in the train set: 63559, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM CV:  20%|██        | 1/5 [00:00<00:01,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 110, number of negative: 63449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2094\n",
      "[LightGBM] [Info] Number of data points in the train set: 63559, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM CV:  40%|████      | 2/5 [00:00<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 110, number of negative: 63449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2101\n",
      "[LightGBM] [Info] Number of data points in the train set: 63559, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM CV:  80%|████████  | 4/5 [00:01<00:00,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 110, number of negative: 63449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2096\n",
      "[LightGBM] [Info] Number of data points in the train set: 63559, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 111, number of negative: 63449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2097\n",
      "[LightGBM] [Info] Number of data points in the train set: 63560, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM CV: 100%|██████████| 5/5 [00:01<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 138, number of negative: 79311\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2158\n",
      "[LightGBM] [Info] Number of data points in the train set: 79449, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "\n",
      "Обучение модели: CatBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CatBoost CV: 100%|██████████| 5/5 [01:09<00:00, 13.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение модели: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost CV:   0%|          | 0/5 [00:00<?, ?it/s]c:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:03:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "XGBoost CV:  20%|██        | 1/5 [00:00<00:01,  3.22it/s]c:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:03:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "XGBoost CV:  40%|████      | 2/5 [00:00<00:00,  3.52it/s]c:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:03:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "XGBoost CV:  60%|██████    | 3/5 [00:00<00:00,  3.64it/s]c:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:03:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "XGBoost CV:  80%|████████  | 4/5 [00:01<00:00,  3.75it/s]c:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:03:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "XGBoost CV: 100%|██████████| 5/5 [00:01<00:00,  3.57it/s]\n",
      "c:\\Prog_tasks\\AI_introd\\hhd_failure_prediction\\aispbenv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:03:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты моделей:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC-AUC (CV)</th>\n",
       "      <th>Precision (CV)</th>\n",
       "      <th>Recall (CV)</th>\n",
       "      <th>F1-Score (CV)</th>\n",
       "      <th>ROC-AUC (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1-Score (Test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9601 ± 0.0195</td>\n",
       "      <td>0.0119 ± 0.0029</td>\n",
       "      <td>0.9206 ± 0.0346</td>\n",
       "      <td>0.0235 ± 0.0056</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9816 ± 0.0277</td>\n",
       "      <td>1.0000 ± 0.0000</td>\n",
       "      <td>0.8767 ± 0.0495</td>\n",
       "      <td>0.9336 ± 0.0283</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.8679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>0.9851 ± 0.0136</td>\n",
       "      <td>1.0000 ± 0.0000</td>\n",
       "      <td>0.7820 ± 0.0633</td>\n",
       "      <td>0.8762 ± 0.0412</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.9505 ± 0.0369</td>\n",
       "      <td>0.9546 ± 0.0428</td>\n",
       "      <td>0.8913 ± 0.0452</td>\n",
       "      <td>0.9214 ± 0.0393</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.9809 ± 0.0083</td>\n",
       "      <td>0.7758 ± 0.0961</td>\n",
       "      <td>0.8913 ± 0.0452</td>\n",
       "      <td>0.8264 ± 0.0610</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9761 ± 0.0201</td>\n",
       "      <td>0.9623 ± 0.0555</td>\n",
       "      <td>0.8556 ± 0.0543</td>\n",
       "      <td>0.9046 ± 0.0461</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model     ROC-AUC (CV)   Precision (CV)      Recall (CV)  \\\n",
       "0  Logistic Regression  0.9601 ± 0.0195  0.0119 ± 0.0029  0.9206 ± 0.0346   \n",
       "1        Random Forest  0.9816 ± 0.0277  1.0000 ± 0.0000  0.8767 ± 0.0495   \n",
       "2          Extra Trees  0.9851 ± 0.0136  1.0000 ± 0.0000  0.7820 ± 0.0633   \n",
       "3             LightGBM  0.9505 ± 0.0369  0.9546 ± 0.0428  0.8913 ± 0.0452   \n",
       "4             CatBoost  0.9809 ± 0.0083  0.7758 ± 0.0961  0.8913 ± 0.0452   \n",
       "5              XGBoost  0.9761 ± 0.0201  0.9623 ± 0.0555  0.8556 ± 0.0543   \n",
       "\n",
       "     F1-Score (CV) ROC-AUC (Test) Precision (Test) Recall (Test)  \\\n",
       "0  0.0235 ± 0.0056         0.8013           0.3235        0.7333   \n",
       "1  0.9336 ± 0.0283         0.9492           1.0000        0.7667   \n",
       "2  0.8762 ± 0.0412         0.9492           1.0000        0.6333   \n",
       "3  0.9214 ± 0.0393         0.9857           1.0000        0.8000   \n",
       "4  0.8264 ± 0.0610         0.9266           1.0000        0.8000   \n",
       "5  0.9046 ± 0.0461         0.9428           1.0000        0.8000   \n",
       "\n",
       "  F1-Score (Test)  \n",
       "0          0.4490  \n",
       "1          0.8679  \n",
       "2          0.7755  \n",
       "3          0.8889  \n",
       "4          0.8889  \n",
       "5          0.8889  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение моделей\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=random_state, max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state, class_weight=\"balanced\"),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(random_state=random_state, class_weight=\"balanced\"),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=random_state, class_weight=\"balanced\"),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=random_state, auto_class_weights=\"Balanced\"),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=random_state,\n",
    "        scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Определение кросс-валидации\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Массив для хранения результатов метрик по каждой моделей\n",
    "results = []\n",
    "\n",
    "# Обучение для каждой модели\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nОбучение модели: {model_name}\")\n",
    "    roc_auc_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Кросс-валидация\n",
    "    for train_idx, val_idx in tqdm(cv.split(X_train, y_train), total=cv.get_n_splits(), desc=f\"{model_name} CV\"):\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Обучение на реальных данных\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Оценка на валидационной выборке (реальные данные)\n",
    "        y_val_pred = model.predict(X_fold_val)\n",
    "        y_val_pred_proba = model.predict_proba(X_fold_val)[:, 1]\n",
    "\n",
    "        roc_auc = roc_auc_score(y_fold_val, y_val_pred_proba)\n",
    "        precision = precision_score(y_fold_val, y_val_pred)\n",
    "        recall = recall_score(y_fold_val, y_val_pred)\n",
    "        f1 = f1_score(y_fold_val, y_val_pred)\n",
    "\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Сохранение средних значений метрик\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"ROC-AUC (CV)\": f\"{np.mean(roc_auc_scores):.4f} ± {np.std(roc_auc_scores):.4f}\",\n",
    "        \"Precision (CV)\": f\"{np.mean(precision_scores):.4f} ± {np.std(precision_scores):.4f}\",\n",
    "        \"Recall (CV)\": f\"{np.mean(recall_scores):.4f} ± {np.std(recall_scores):.4f}\",\n",
    "        \"F1-Score (CV)\": f\"{np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\",\n",
    "    })\n",
    "\n",
    "    # Финальное тестирование на реальных данных\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    test_metrics = {\n",
    "        \"ROC-AUC (Test)\": roc_auc_score(y_test, y_test_pred_proba),\n",
    "        \"Precision (Test)\": precision_score(y_test, y_test_pred),\n",
    "        \"Recall (Test)\": recall_score(y_test, y_test_pred),\n",
    "        \"F1-Score (Test)\": f1_score(y_test, y_test_pred),\n",
    "    }\n",
    "\n",
    "    # Добавление тестовых метрик в финальные результаты\n",
    "    results[-1].update({key: f\"{value:.4f}\" for key, value in test_metrics.items()})\n",
    "\n",
    "# Вывод таблицы результатов\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nРезультаты моделей:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results/models_results_weighted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводим результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/models_results_resampled.csv') as f:\n",
    "    res = pd.read_csv(f)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/models_results_weighted.csv') as f:\n",
    "    res = pd.read_csv(f)\n",
    "\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aispbenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
